{
    "PROJECT_NAME": "Seoul Temprature Prediction",
    "GITHUB_USERNAME": "Sambonic",
    "REPO_NAME": "seoul-temprature-prediction",
    "PROJECT_DESCRIPTION": "This project uses machine learning to predict minimum air temperatures.\n",
    "PROJECT_FEATURES": "- **Air Temperature Prediction:** Predicts next-day minimum air temperature using machine learning.\n- **Data Exploration and Visualization:**  Loads, cleans, and visualizes air temperature data, including exploratory data analysis (EDA) and visualizations of temperature distributions, trends, and correlations with geographical and environmental factors.\n- **Data Preprocessing:** Handles missing values (mean/median imputation) and outliers (IQR and Z-score methods) in the dataset.\n- **Feature Engineering:** Creates new features from existing data (e.g., year, month, season, daily temperature range).\n- **Feature Selection:** Employs different feature selection methods (Sequential Feature Selection (SFS), Sequential Backward Selection (SBS), SelectKBest) to identify the most relevant features for prediction.\n- **Model Training and Evaluation:** Trains and evaluates multiple regression models (Random Forest, Linear Regression, LightGBM) using metrics such as RMSE, MAE, and R\u00b2.  Includes hyperparameter tuning using GridSearchCV and learning curves to assess model performance.\n- **Model Comparison:** Compares the performance of different models with and without feature selection and hyperparameter tuning using bar charts.\n\n",
    "PROJECT_USAGE": "1. **Run the notebook:** Execute all cells in `air_temprature_prediction_ml.ipynb`. This performs data loading, cleaning, exploration, model training, and evaluation.\n\n2. **Interpret results:** Observe generated visualizations (histograms, scatter plots, heatmaps, learning curves, and bar charts) to understand data distributions, relationships between features, model performance, and the impact of feature selection and hyperparameter tuning.  Review printed metrics (RMSE, MAE, R\u00b2) for each model to compare performance. The notebook provides a legend to interpret model names.  The bar charts compare model performance across different metrics and configurations (with/without feature selection and hyperparameter tuning).\n"
}