{
    "PROJECT_NAME": "Seoul Temprature Prediction",
    "GITHUB_USERNAME": "Sambonic",
    "REPO_NAME": "seoul-temprature-prediction",
    "PROJECT_DESCRIPTION": "This project uses machine learning to predict next-day minimum air temperatures.\n",
    "PROJECT_FEATURES": "- **Air Temperature Prediction:** Predicts next-day minimum air temperature using machine learning.\n- **Data Exploration and Visualization:**  Includes data loading, statistical analysis, and visualization of temperature trends, distribution, and correlations with geographical and environmental factors (elevation, slope, solar radiation).\n- **Data Preprocessing:** Handles missing values (mean/median imputation) and outliers (IQR and Z-score methods).  Creates new features from date information (year, month, season, daily temperature range).\n- **Feature Engineering:**  Derives additional features such as `Daily_Temp_Range` and date-based features.\n- **Feature Selection:**  Experiments with different feature selection methods (Sequential Feature Selection - forward and backward, SelectKBest) to optimize model performance.\n- **Model Training and Evaluation:** Trains and evaluates multiple regression models (Random Forest, Linear Regression, LightGBM).  Uses metrics like RMSE, MAE, and R-squared for model evaluation.  Includes hyperparameter tuning using GridSearchCV.\n- **Learning Curve Analysis:**  Plots learning curves to assess model bias and variance.\n- **Model Comparison:** Compares the performance of different models with and without feature selection and hyperparameter tuning, visualizing results using bar charts.\n\n",
    "PROJECT_USAGE": "1.  **Run the notebook:** Execute all cells in `air_temprature_prediction_ml.ipynb`. This will load the dataset, perform exploratory data analysis (EDA), handle missing values, and train several machine learning models to predict the next day's minimum temperature.\n\n2.  **Observe EDA results:** The notebook generates various visualizations (histograms, box plots, scatter plots, heatmaps) and descriptive statistics.  These aid in understanding the dataset's characteristics and identifying potential issues like missing data or outliers.\n\n3.  **Examine data preprocessing:** The code shows how missing values are imputed using median and mean imputation strategies. Outlier treatment is also demonstrated via z-score and IQR methods.\n\n4.  **Evaluate model performance:** Multiple regression models (Random Forest, Linear Regression, LightGBM) are trained and evaluated using metrics like RMSE, MAE, and R\u00b2. The notebook displays the performance of each model with and without feature selection and hyperparameter tuning.\n\n5.  **Analyze learning curves:** Learning curves are plotted for each model, illustrating the trade-off between model complexity and generalization ability.\n\n6.  **Compare model performance:**  The notebook provides bar charts comparing the performance of different models across various metrics, facilitating the selection of the best-performing model for the prediction task.  A legend is provided to decipher the model names.\n"
}