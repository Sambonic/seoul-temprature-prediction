{
    "PROJECT_NAME": "Seoul Temprature Prediction",
    "GITHUB_USERNAME": "Sambonic",
    "REPO_NAME": "seoul-temprature-prediction",
    "PROJECT_DESCRIPTION": "This project uses machine learning to predict minimum air temperatures.\n",
    "PROJECT_FEATURES": "- **Air Temperature Prediction:** Predicts next-day minimum air temperature using machine learning.\n- **Data Exploration and Visualization:**  Loads, cleans, and visualizes the dataset using various plots (histograms, scatter plots, box plots, heatmaps) to understand data distribution, trends, and relationships between features.\n- **Data Preprocessing:** Handles missing values (mean/median imputation) and outliers (IQR and Z-score methods).\n- **Feature Engineering:** Creates new features from existing ones (e.g., year, month, season, daily temperature range).\n- **Feature Selection:** Employs feature selection techniques (Sequential Feature Selection (SFS), Sequential Backward Selection (SBS), SelectKBest) to identify the most relevant features for prediction.\n- **Model Training and Evaluation:** Trains and evaluates multiple regression models (Random Forest, Linear Regression, LightGBM) using metrics like RMSE, MAE, and R\u00b2.\n- **Hyperparameter Tuning:** Uses GridSearchCV to optimize model hyperparameters.\n- **Learning Curve Analysis:** Plots learning curves to assess model performance and identify potential overfitting.\n- **Model Comparison:** Compares the performance of different models and feature selection strategies.\n\n",
    "PROJECT_USAGE": "1. **Run the notebook:** Execute the `air_temprature_prediction_ml.ipynb` Jupyter Notebook.  This performs data loading, preprocessing, exploratory data analysis (EDA), model training (using Random Forest, Linear Regression, and LightGBM), hyperparameter tuning, and model evaluation.\n\n2. **Examine results:** The notebook outputs visualizations (histograms, scatter plots, heatmaps, learning curves) during EDA and model evaluation.  Numerical results (RMSE, MAE, R-squared) for each model are displayed in the notebook's output.  A series of bar charts compare the performance of the different models across various metrics and configurations (with/without feature selection and hyperparameter tuning).  The notebook also provides a legend to interpret the model names.\n"
}